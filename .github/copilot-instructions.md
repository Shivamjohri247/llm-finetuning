<!-- Use this file to provide workspace-specific custom instructions to Copilot. For more details, visit https://code.visualstudio.com/docs/copilot/copilot-customization#_use-a-githubcopilotinstructionsmd-file -->

This project is a production-ready Python pipeline for fine-tuning LLMs (LLaMA-2 or Gemma) using Unsloth with LoRA/QLoRA, ONNX/TensorRT export, Triton Inference Server deployment, and FastAPI/Gradio inference. Organize code into data/, train/, optimize/, serve/, utils/.
